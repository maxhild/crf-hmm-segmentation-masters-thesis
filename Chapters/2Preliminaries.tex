%*****************************************
\chapter{Grundlagen}\label{ch:preliminaries}
%*****************************************

In diesem Kapitel werden die medizinischen und technischen Grundlagen erläutert, die für das Verständnis der Arbeit notwendig sind.
Dabei wird zuerst auf die medizinischen Hintergründe des behandelten Problems eingegangen.
Anschließend werden das technische Fundament der Segmentierung sowie gängige Bildgebungsverfahren behandelt, die zur Lösung des Problems eingesetzt werden können.
Dabei sollen Markov Modelle mit Methoden aus der Signal- und Bildverarbeitung kombiniert werden, um eine robuste Segmentierung von Endoskopievideos zu ermöglichen.
Die der technischen Implementierung zugrundeliegenden mathematischen Hintergründe und Theoreme werden ebenfalls in diesem Kapitel vorgestellt, um die theoretische Basis der Arbeit zu untermauern.

\section{Medizinischer Hintergrund}
Endoskopie ist eine der zentralen Behandlungs- und Diagnosemöglichkeiten in der Therapie von Darmkrebs, 
einer der häufigsten und tödlichsten Krebsarten.\citep{labianca2010-colon-cancer}\footnotemark{} 
Nicht von der Hand zu weisen ist hierbei die zeitaufwändige Durchführung und 
Dokumentation der Überwachung des flächigen Gewebes im Darm im Rahmen von Endoskopien. Aus diesem Grund ist es 
der Gastroenterologie konstant ein Anliegen, die Qualitätssicherung bei Darmspiegelungen zu verbessern. 
Wie in der Einleitung erwähnt, ist die Zökum-Rückzugszeit ein Beispiel für ein zuverlässiges Qualitätsmerkmal.  Hierbei ist es wichtig, dass die Darmspiegelung eine vorgeschriebene Zeit dauert, um die Chance auf eine vollständige Detektion aller möglichen Adenome zu erhöhen. 
Dadurch steigt die Wahrscheinlichkeit, dass die Darmspiegelung sorgfältig durchgeführt wurde, was nachweislich zu einer 
erhöhten Anzahl frührer Diagnosen führt und somit Todesfälle verhindern kann. Das liegt daran, dass die Durchführung von Darmspiegelungen sorgfältiger wird, wenn 
die Zeitvorgaben eingehalten werden.
Dieses Beispiel zeigt, dass wenn Qualitätskriterien eingehalten werden die Behandlungsqualität steigen kann. 
Die Europäische Gesellschaft für Gastroenterologie (ESGE) hat hierzu einige Forschungsfragen herausgegeben. Hierbei gibt es einige Punkte, speziell während der Endoskopie sowie in der Nachbereitung des Videomaterials, als auch weitergehend deren Umsetzung durch Nutzung eines KI-gestützten Systems zur Qualitätssicherung bei Darmspiegelungen profitieren könnten:

\begin{enumerate}
  \item \textbf{Vorbereitung der Prozedur}
    \begin{itemize}
      \item Welche Art von Intervention verbessert die Rate einer adäquaten Darmvorbereitung?
      \item Wie viel Zeit sollte für Screening- und diagnostische Koloskopien eingeplant werden?
    \end{itemize}

  \item \textbf{Vollständigkeit der Prozedur}
    \begin{itemize}
      \item Wie verhalten sich diagnostische Ausbeute (und Intervallkarzinomrate) in Abhängigkeit von einer steigenden Zökumintubationsrate?
      \item Welchen Nutzen hat die Dokumentation der Zökumintubation nur im schriftlichen Bericht im Vergleich zu einem schriftlichen \emph{und} fotografischen Bericht?
    \end{itemize}

  \item \textbf{Identifikation von Pathologien}
    \begin{itemize}
      \item Welcher Zielwert gilt für die Adenomdetektionsrate?
      \item Welches Leistungsmaß spiegelt die Identifikation von Pathologien außerhalb des CRC-Screening-/Überwachungssettings wider?
    \end{itemize}

  \item \textbf{Management von Pathologien}
    \begin{itemize}
      \item Was ist die verlässlichste und praktikabelste Methode, um die Vollständigkeit der Polypentfernung zu messen?
      \item Wie wirksam sind Zusatztechniken/-skalen (Chromendoskopie, Paris-Klassifikation, Tätowierung von Resektionsstellen) im Management von Pathologien?
    \end{itemize}

  \item \textbf{Komplikationen}
    \begin{itemize}
      \item Was ist die verlässlichste und praktikabelste Methode, um Komplikationsraten zu überwachen?
      \item Trägt die Überwachung dazu bei, Komplikationsraten zu senken?
    \end{itemize}
\end{enumerate}
\citep{kaminski-performance-2017}

Eine Motivation für ein zuverlässiges Segmentationsmodell für Endoskopievideos ist es, 
dass die Zökum-Rückzugszeit automatisch berechnet werden könnte. Wenn anhand der Vorhersage des letzten Frames, 
der innerhalb des Körpers gefunden wird, festgestellt ist, ist die untere Schranke für den der Berechnung zugrundeliegenden Abschnitt des 
Videos bereits gegeben. Für die Berechnung der Zäkum-Rückzugszeit würde sich das so errechnete Upper Bound bei den Frames in dem Moment eignen, 
in dem auch das Zäkum vertrauenswürdig erkannt wird. Die zuverlässige Erkennung von Organteilen des Darms im Video ist 
Teil der endoskopischen Forschung mit künstlicher Intelligenz. Im speziellen die Erkennung von Polypen ist von besonderem Interesse. 
Diese Geschwulste wachsen als Vorstufe von potenziell bösartigen Tumoren an der Darminnenwand. Sie können aus verschiedenen Gründen und in verschiedenen Darmteilen auftreten, 
sind jedoch besonders als Frühmerkmal einer möglichen Diagnose von Darmkrebs interessant und deshalb wenn möglich vollständig zu erkennen. \citep{doi:10.7326/0003-4819-157-4-201208210-00002}
Weiter kompliziert wird die Erkennung und Einschätzung von Polypen dadurch, dass es verschiedene Stufen gibt.
Während bei einigen kolorektalen Polypen eine Darmblutung als Symptom auftritt, die zumeist eine schnelle Diagnose ermöglicht, sind andere Polypen asymptomatisch und werden nur zufällig bei einer routinemäßigen Darmspiegelung entdeckt.
Besonders bei diesen Fällen kann das Risiko bestehen, dass Polypen übersehen werden.
Unterschieden wird hierbei zwischen hochgradigen und niedergradigen Dysplasien. Diese Stufen bezeichnen den Grad der Zellveränderung in der Region des Polypen.
Besonders bei höhergradigen Dysplasien besteht das Risiko, dass ein maligner Polyp vorliegt.
Definitiv kann dies durch den Nachweis karzinogener Zellen innerhalb eines Polypen festgestellt werden. Hierbei handelt es sich um eine Aufgabe für die Pathologie,
die nach vollständiger Entfernung des betroffenen Gewebes erfolgen kann. \citep{Colucci261}
Auch bei der Zökum-Rückzugszeit ist das zentrale Kriterium, dass möglichst wenige Polypen übersehen werden sollen. 
Da durch den Einsatz von automatischer Erkennung dieser Vorkommnisse innerhalb des Darms eine erhebliche Beschleunigung dieses 
Prozesses möglich wäre, wird in diesem Bereich bereits seit Jahren geforscht. \citep{talukder-2022} 

Die Inferenz mit CNN basierten Modellen wie ResNet50 oder EfficientNetB0 hat sich in den letzten Jahren als sehr erfolgreich erwiesen.
Diese Modelle sind in der Lage, Bilddaten zu klassifizieren und können auch für die Segmentierung von Videos als Frames genutzt werden.
Die Ergebnisse dieser Klassifikation sind bei ausreichendem Training in einer kontinuierlichen Pipeline nutzbar.

\subsection{Assistierte Dokumentation von Endoskopievideos}

Lux et. al \citet{lux-2023} beschreiben ein Verfahren zur automatisierten Dokumentation von Endoskopievideos. Dabei wird ein auf Deep Learning basierendes System eingesetzt, um relevante Informationen aus den Videos zu extrahieren und in strukturierter Form bereitzustellen. Das System nutzt Convolutional Neural Networks (CNNs), um verschiedene Merkmale in den Endoskopiebildern zu erkennen, wie z.B. Polypen, Läsionen oder anatomische Strukturen. Die extrahierten Informationen werden dann in einem Bericht zusammengefasst, der dem Arzt bei der Diagnose und Behandlung unterstützt. Die Autoren zeigen, dass das System eine gute Genauigkeit bei der Erkennung relevanter Merkmale aufweist und somit die Effizienz und Qualität der Endoskopiedokumentation verbessern kann.

Das Ziel dieser Publikation war es, eine Methode zur assistierten Dokumentation zu präsentieren, die Labels mit dazugehörigen Frames verknüpft und somit eine strukturierte Übersicht über das Videomaterial bietet. Dies ist besonders relevant für die Nachbereitung von Endoskopien, da Ärzte so schneller auf wichtige Informationen zugreifen können. Die Autoren betonen, dass eine solche assistierte Dokumentation nicht nur die Effizienz steigert, sondern auch die Genauigkeit der Berichte verbessert, indem menschliche Fehler reduziert werden. Die weitere Entwicklung der assistierten Dokumentation wird als neuer Fokus vorgeschlagen. Diese Empfehlung deckt sich weitestgehend mit der Zielsetzung aus Kaminski et. al \citet{kaminski-performance-2017}, die in ihrer Publikation Forschungsfragen zur Verbesserung der Qualitätssicherung bei der Bewertung der Vollständigkeit von Darmspiegelungen durch Dokumentation aufstellen. Hierbei kann also als Optimierung angenommen werden, dass sich diese vor entweder durch Verbesserung von korrekter Segmentierung der Frames eines Videos oder durch eine Beschleunigung der Verarbeitung und das Nutzbar machen der automatisierten Dokumentation durch Beschleunigung erreichen lässt.  

\section{Technische und mathematische Grundlagen}

Dieses Kapitel wird die Herangehensweise an die mathematische Modellierung der Segmentierung von Endoskopievideos erläutern.
In diesem Kontext soll später im Kapitel Methodik herausgearbeitet werden, welche Modelle sich für eine statistisch haltbare Bewertung von Frameregionen eignen. Da es sich bei einer Endoskopie, wie in Lux et al. demonstriert, um eine Intervention handelt, die sich in Phasen, beziehungsweise Zustände einteilen lässt, wurde der Fokus auf Zustandsbasierte Modelle wie Markovmodelle gelegt.

\subsubsection{Markovprozesse - Eine Methode um abhängige Variablen probabilistisch zu quantisieren.}

\enquote{Wir betrachten ein zufälliges dynamisches System. Sei $S : \mathbb{R} \to \mathbb{R}$ ein dynamisches System und definieren einen stochastischen Prozess $\{X_n\}_{n \ge 0}$ durch $X_{n+1} = S(X_n) + Y_n$, wobei $Y_0, Y_1, \dots$ unabhängige Zufallsvariablen mit Werten in $\mathbb{R}$ sind, die jeweils die gleiche Dichte $g$ haben, und $X_0$ und $\{Y_n\}_{n \ge 0}$ unabhängig sind. Dann ist der stochastische Prozess $\{X_n\}$ ein Markov-Prozess.} \citep[S.~13]{KhalilGhaffari2023}
Markov Prozesse sind laut dieser Definition Systeme aus Zuständen, die sich über die Zeit verändern.
Sie dürfen dabei nur von dem aktuellen Zustand abhängen und nicht von den vorherigen Zuständen.
Die Definition bezieht sich auf ein Stochastisches System und sieht deshalb eine Normierung der Werte im Bereich 0 bis 1 vor.
Die Zustände des Systems werden durch die Zufallsvariablen $X_n$ beschrieben.
\newline
Der Name der Markov-Prozesse stammt aus der Arbeit von A. A. Markov. Insbesondere interessant ist hier die Publikation \enquote{Beispiel von statistischer Forschung auf einem Text von \enquote{Eugene Onegin}, der interkonnektivität abhängiger Versuche in einer Kette klassifiziert.} \citep{markov1913onegin}.
Anhand eines Gedichts und der Verteilung der Konsonanten und Vokale untersuchte Markov hier, ob durch vielfache Wiederholung eines Zufallsexperiments, bei dem die Versuche voneinander abhängig sind, eine statistische Vorhersage getroffen werden kann. Dieser empirische Beweis greift eine frühere Publikation seinerseits auf, die theoretisch darlegt, dass das Gesetz der großen Zahlen auch auf abhängige
Zufallsvariablen anwendbar ist. Durch empirisches Messen der Häufigkeiten der Variablen erfasste Markov eine Übergangswahrscheinlichkeit. 
\begin{equation}
p_{ij} = P(X_{n+1} = j \mid X_n = i),
\quad \text{mit} \quad \sum_j p_{ij} = 1.
\label{eq:transition_prob}
\end{equation}
Diese konnte er im Nachgang einsetzen, um über diese Wahrscheinlichkeiten wiederum eine Buchstabenfolge zu generieren, bei der die Anzahl der Konsonanten und Vokale wieder auf einem Niveau einpendelten, das mit dem russischen Originaltext vergleichbar war.
Ausgang für diese Untersuchung war die These von Pawel Nekrasov. Dieser hatte in seiner „Theorie der Wahrscheinlichkeit“ angezweifelt, dass probabilistische Modelle in Untersuchungen von abhängigen Variablen wie sozialen Zusammenhängen angewandt werden könnten, weil abhängige Größen nur durch den freien Willen und nicht durch Naturgesetze beeinflusst sind. Ilona Svetlikova beschreibt in der Sekundäranalyse von Nekrasov die philosophisch-theologische Haltung hinter Nekrasovs Argumentation.
Laut Svetlikova argumentiert Nekrasov, dass Wahrscheinlichkeitsgesetze Ausdruck des göttlichen Willens seien und daher nicht auf abhängige oder soziale Prozesse angewandt werden dürften - da diese den freien Willen der Menschen widerspiegeln.\citep{svetlikova2013nekrasov} Diese These stützte Nekrasov auf Beobachtungen, dass bei sozialen Statistiken wie der Rate der Hochzeiten in einer Gesellschaft in aufeinanderfolgenden Jahren oft ähnliche Hochzeitsraten auftreten obwohl sich die gesellschaftlichen Bedingungen ändern. \citep{nekrasov1912} Durch Markovs empiririschen Beweis seiner theoretischen Grundlagenpublikation \citet{markov1906extension} zeigte er, dass auch abhängige Variablen in oft wiederholten Zufallsexperimenten messbare Gesetzmäßigkeiten aufzeigen können.  Diese Idee wurde weiterentwickelt, um durch passende Modelle effiziente Vorhersagen über zukünftige Ereignisse treffen zu können.
Seine Arbeit hat bis heute großen Einfluss und begründete die Klasse der Markovprozesse. Diese sind und findet sich auch in aktuellen Entwicklungen wie Recurrent Neural Networks wieder.

In seinem Einführungswerk beschreibt A. W. Drake Markovprozesse in diskreter Zeit und mit diskreter Zustandsmenge. Er definiert sie allgemein als Kette von Zuständen $S$, deren zukünftige Entwicklung nur vom aktuellen Zustand abhängt und deren Übergänge durch Übergangswahrscheinlichkeiten bestimmt werden. Eine Bedingung für das Vorliegen eines Markovprozesses wird so definiert als \begin{equation}
P(X_{n+1} = x_{n+1} \mid X_n = x_n, X_{n-1} = \newline x_{n-1}, \dots, X_0 = x_0)
= P(X_{n+1} = x_{n+1} \mid X_n = x_n)
\label{eq:markov_property}
\end{equation}.
Weitergehend ist die zweite Eigenschaft der Übergangswahrscheinlichkeiten ausgehend von einem aktuellen Prozess, dass die ausgehenden Wahrscheinlichkeiten des Prozesses sich zu eins addieren sollten damit es sich hierbei um eine vollständige Abbildung aller möglichen Zustände handelt.
\begin{equation}
  \sum_j P_{ij} = 1.
\end{equation}
Wobei $P_{ij}$ die Wahrscheinlichkeit beschreibt, dass das System, nachdem der aktuelle Zustands $S_i$ ist, in den nächsten Zustand $S_j$ übergehen wird.\citet{drake88}

Generalisiert kann davon gesprochen werden, dass ein Markovprozess sich aus dem Zustandsraum $\Omega$ zusammensetzt, der alle möglichen Zustände des Systems umfasst. Die einzelnen Zustände $S_i$ oder $\omega$ sind Elemente dieses Zustandsraums $\omega~\Omega$. Genauso gilt für die Wahrscheinlichkeiten $P(X_{n})$ dass Sie Elemente des Wahrscheinlichkeitsraums $\mathcal{P}$ sind. Auch die Zeit $\{n\}$, in der sich die Zustände ändern, kann als Element eines Zeitraums $\mathcal{T}$ betrachtet werden. Somit lässt sich ein Markovprozess als Tripel $(\Omega, \mathcal{P}, \mathcal{T})$ beschreiben.

\subsection{Arten von Systemen modellierbar durch Markovprozesse.}

Ein Markovprozess kann generell 
Generell können eine Vielzahl von Systemen durch Markovprozesse modelliert werden. Es gibt jedoch Unterschiede bei der Komplexität sowie bei der mathematischen Beweislage auf. Während Markovprozesse auf wwohldefiniert sind auf

\subsection{Invarianz von Maßen und stationäre Verteilungen in Markovprozessen - Messen der langfristigen Stabilität von Systemen}

Ein häufig auftretendes Problem bei der Modellierung von kontinuierlichen Systemen ist es, dass ein System, wenn es langfristig betrachtet wird oftmals eine stationäre Verteilung erreicht. Das beschriebene Phänomen ist der Ruin des Spielers, der Gamblers Ruin. Dieses berühmte Problem trägt den Namen, da bei der Analyse von Glücksspielen entdeckt wurde, dass bekannte Glücksspiele wie Roulette oder Poker, die wiederholt mit einem jede Runde reinvestierten Startkapital gespielt werden, langfristig immer der finanzielle Ruin eines Spielers führen. Es kann dabei durch den Aufbau sowie das Startkapital sowie den Einsatz des Spiels lediglich die Länge des Spiels beeinflusst werden, nicht jedoch das Endergebnis. Wie J.L. Coolidge zeigen konnte, ist der genaue Zeitpunkt des Ruins eines Spielers wird unbekannt, liegt jedoch stets innerhalb eines definierbaren Limits. \citep{coolidge1909gamblers}

Angenommen $\mu$ ist die Verteilung des Gewichts $\omega\epsilon\Omega$ eines Objekts zu einem Zeitpunkt $t$ wobei $\Omega$ die Menge aller möglichen Gewichte, der Zustandsraum ist. Es wird von einem Gewicht der Kante $i$ zu einem Gewicht der Kante $j$ übergegangen mit der Wahrscheinlichkeit $P_{ij}$.
Wenn der Zustand $\omega$ zufällig und mit der Verteilung $\mu$ verteilt ist, und die angenommene Wahrscheinlichkeit für $\mu$ gleich wie die $P_\mu$ ist, dann wird eine P-invariante Verteilung $P_\mu = \mu$ genannt. Der Nachweis der theoretischen Existenz von Invarianz bei  \citep{Lester1966}

Aus dieser Definition der Verteilung und ihrer Konvergenz in Markovsystemen, in denen die Anzahld er Versuche gegen Unendlich geht entstand eine weitere Maßeinheit von Markovsystemen. Um zu determinieren, wie sich das System langfristig verhalten wird, muss festgestellt werden ob es Ergozität aufweist. Die Prozesse gelten als ergozid, wenn es einen stabilen Zustand gibt, in den das System konvergiert, unabhängig vom Anfangszustand. \cite{MeynTweedie1993}

Wenn die wahre Verteilung $\mu$ und die dazugehörige Übergangswahrscheinlichkeit $P_\mu$ in der Praxis nicht bekannt sind, wird eine geschätzte Verteilung $\pi$ und die dazugehörige Übergangswahrscheinlichkeit $P_\pi$ genutzt. Um ein stabil


\subsection{Sequenzielle Datenmodellierung mit Markovprozessen.}

Die Modellierung sequenzieller Daten ist ein wichtiger Aspekt in vielen Bereichen der Informatik und Statistik, insbesondere in der Verarbeitung natürlicher Sprache, Zeitreihenanalyse und Bioinformatik. Sequenzielle Daten bestehen aus einer geordneten Folge von Elementen, bei denen die Reihenfolge der Elemente eine entscheidende Rolle spielt. Beispiele für sequenzielle Daten sind Textdokumente, DNA-Sequenzen und Zeitreihen von Messwerten.
Basierend auf der Entdeckung von Markov, wurden hierfür vielfältige Erweiterungen mit weitreichenden Anwendungen konzipiert.
Markovmodelle zielen darauf ab, die Abhängigkeiten zwischen aufeinanderfolgenden unabhängigen Zuständen in einer Sequenz zu erfassen.

Für die 1-Schritt-Übergangsmatrix $P$ gilt per Definition:
\begin{equation}
P_{ij} = P(X_{t+1} = j \mid X_t = i).
\end{equation}

Für eine 2-Schritt-Übergangswahrscheinlichkeit $P(X_{t+2} = j \mid X_t = i)$ müssen wir einen Zwischenzustand $k$ beachten:
\begin{equation}
P(X_{t+2} = j \mid X_t = i) = \newline \sum_k P(X_{t+1} = k \mid X_t = i) \cdot P(X_{t+2} = j \mid X_{t+1} = k).
\end{equation}

Die Übergangswahrscheinlichkeiten können in einer Matrix $P$ zusammengefasst werden, wobei die Einträge $P_{ij}$ die Wahrscheinlichkeit angeben, vom Zustand $i$ in den Zustand $j$ überzugehen. Die Matrix $P$ wird als Übergangsmatrix bezeichnet und hat die Eigenschaft, dass die Summe der Einträge in jeder Zeile gleich 1 ist, da sie die gesamten Übergangswahrscheinlichkeiten von einem Zustand zu allen möglichen Zuständen repräsentiert.

In der Definition nimmt das Modell ein vollständig abgebildetes stochastisches Zufallsexperiment an. Es wird zudem davon ausgegangen, dass die Zustände des Systems vollständig beobachtbar sind. Einer einfachen Definition folgend, müsste so für jedes Label $y_i$ eines Frames $x_i$ die Wahrscheinlichkeit $P(y_i \mid x_i)$ modelliert werden. \citet{drake88}

\subsection{Markovketten in diskreter Zeit zur Modellierung von Systemen mit endlichem Zustandsraum.}

Eine Markovkette ist ein Spezialfall eines Markovprozesses mit diskreten Zeitpunkten und endlichem Zustandsraum. 
Sei $S = \{s_1, s_2, \dots, s_N\}$ die Menge der möglichen Zustände.
Die Folge $\{X_t\}_{t \ge 0}$ heißt Markovkette, wenn für alle $t \ge 0$ gilt:
\begin{equation}
P(X_{t+1} = s_j \mid X_t = s_i, X_{t-1}, \dots, X_0)
= P(X_{t+1} = s_j \mid X_t = s_i).
\end{equation}

Die Wahrscheinlichkeiten $P_{ij} = P(X_{t+1} = s_j \mid X_t = s_i)$ bilden die
\emph{Übergangsmatrix} $P \in \mathbb{R}^{N \times N}$.
Jede Zeile von $P$ ist normiert, d.\,h.
\begin{equation}
\sum_{j=1}^{N} P_{ij} = 1, \quad \forall i.
\end{equation}

\paragraph{Anfangsverteilung.}
Die Wahrscheinlichkeiten, mit denen das System in einem Zustand startet, werden durch den Vektor $\pi = (\pi_1, \ldots, \pi_N)$ beschrieben, wobei $\pi_i = P(X_0 = s_i)$ gilt.

\paragraph{n-Schritt-Übergänge.}
Für $n > 1$ ergibt sich die Anzahl der Felder der $n$-Schritt-Übergangsmatrix durch Potenzieren:
\begin{equation}
P^{(n)} = P^n.
\end{equation}

\paragraph{Stationäre Verteilung.}
Eine Verteilung $\pi^*$ heißt \emph{stationär}, wenn sie unter Anwendung der Übergangsmatrix invariant bleibt:
\begin{equation}
\pi^* = \pi^* P.
\end{equation}

\paragraph{Beispiel.}
Für ein zweizuständiges System mit Zuständen „Innen“ und „Außen“ im Endoskopievideo sei
\[
P = \begin{pmatrix}
0.9 & 0.1 \\
0.3 & 0.7
\end{pmatrix}.
\]
Dann beschreibt $P_{12} = 0.1$ die Wahrscheinlichkeit, dass ein Frame vom Typ „Innen“ im nächsten Schritt zu „Außen“ wechselt.


\subsection{Markov Modelle}

Markov Modelle sind eine Klasse von statistischen Modellen, die verwendet werden, um Systeme zu modellieren, die sich über die Zeit verändern. Sie basieren auf der Annahme, dass der zukünftige Zustand eines Systems nur vom aktuellen Zustand abhängt und nicht von den vorherigen Zuständen. Dies wird als Markov-Eigenschaft bezeichnet.
Die Modelle werden als \enquote{Hidden} bezeichnet, wenn die zugrunde liegenden Zustände nicht direkt beobachtet werden, sondern nur durch beobachtbare Ausgaben oder Emissionen inferiert werden.
\newline
Generell handelt es sich bei HMM um ein generatives Modell, es wird also eine Wahrscheinlichkeit basierend auf dem zugrundeliegenden gelernten System abgebildet.
$P(X, Y)$


\subsection{Conditional Random Fields als generalisiertes Markov-Modell}

Conditional Random Fields (CRF) beschreiben eine Klasse von Modellen, mit denen sich Übergangswahrscheinlichkeiten darstellen lassen. Generell handelt es sich bei CRF um ein diskriminatives Modell, es wird also direkt die bedingte Wahrscheinlichkeit $P(Y|X)$ der Ausgabevariablen $Y$ gegeben die Eingabevariablen $X$ modelliert, anstatt der gemeinsamen Wahrscheinlichkeit $P(X, Y)$.
Diese Modellklasse ist die generalisierte Form von Markov Models. Hidden Markov Models beschreiben, wie im Kapitel erläutert, die Annahme, dass aufgrund von dem vorherigen versteckten Zustand das System vorhergesagt werden kann. Hierfür müsste jedoch das System von der Menge der versteckten Zustände vollständig beobachtbar sowie abbildbar sein.

\subsection{Non Markov Modelle}



\subsection{Chapman-Kolmogorov-Gleichung}

Die Chapman-Kolmogorov-Gleichung beschreibt, wie die Übergangswahrscheinlichkeit eines Markov-Prozesses über mehrere Zeitschritte hinweg berechnet werden kann. 
Dabei wird ein möglicher Zwischenzustand $k$ zu einem Zeitpunkt $m$ berücksichtigt, sodass die Wahrscheinlichkeit für einen Übergang von Zustand $i$ zu Zustand $j$ nach $n+m$ Schritten über die Gesamtheit aller Zwischenzustände dargestellt werden kann.

Für einen Markov-Prozess $\{X_t\}_{t \geq 0}$ mit Zustandsraum $S$ gilt für alle $i, j \in S$ und $n, m \geq 0$:
\begin{equation}
P(X_{n+m} = j \mid X_0 = i) = \sum_{k \in S} P(X_{n+m} = j \mid X_m = k, X_0 = i) \cdot P(X_m = k \mid X_0 = i).
\end{equation}

Mit Hilfe der Markov-Eigenschaft vereinfacht sich der erste Term, da der zukünftige Zustand $X_{n+m}$ nur vom aktuellen Zustand $X_m$ abhängt, nicht aber vom gesamten Verlauf bis $X_0 = i$:
\begin{equation}
P(X_{n+m} = j \mid X_m = k, X_0 = i) = P(X_{n+m} = j \mid X_m = k).
\end{equation}

Damit ergibt sich die Chapman-Kolmogorov-Gleichung in der üblichen Form:
\begin{equation}
P(X_{n+m} = j \mid X_0 = i) = \sum_{k \in S} P(X_{n+m} = j \mid X_m = k) \cdot P(X_m = k \mid X_0 = i).
\end{equation}

Schreibt man die Übergangswahrscheinlichkeiten in Matrixform, so entspricht dies der Aussage:
\begin{equation}
P^{(n+m)} = P^{(m)} \cdot P^{(n)},
\end{equation}
wobei $P^{(r)}$ die $r$-Schritt-Übergangsmatrix bezeichnet.

Über eine solche Übergangsmatrix können Vorhersagen über zukünftige Zustände eines Markov-Prozesses getroffen werden, indem die Matrix potenziert wird.
Das bedeutet, dass die $n$-Schritt-Übergangsmatrix $P^{(n)}$ durch die $n$-fache Multiplikation der 1-Schritt-Übergangsmatrix $P$ mit sich selbst berechnet werden kann:
\begin{equation}
P^{(n)} = \underbrace{P \cdot P \cdot \cdots \cdot P}_{n \text{ Mal}} = P^n.
\end{equation} 


\subsection{Viterbi-Dekodierung}

Der Viterbi-Algorithmus ist ein dynamischer Programmieralgorithmus, der verwendet wird, um die wahrscheinlichste Sequenz von versteckten Zuständen in einem Hidden Markov Model (HMM) zu finden, basierend auf einer gegebenen Sequenz von beobachteten Ereignissen. Der Algorithmus wurde von Andrew Viterbi 1967 \citet{viterbierror},
erstmals vorgeschlagen und ist besonders nützlich in Anwendungen, bei denen sequenzielle Daten auftreten, deren Zusammensetzung Schlüsse auf die zugrundeliegenden wahren Zustände zulassen. Die Fähigkeit, aus den beobachtbaren Zuständen auf versteckte Wahrheiten schließen zu können, macht den Viterbi-Algorithmus praxisrelevant in vielen Bereichen, wie in der Elektrotechnik bei der Analyse von Kommunikationssystemen oder in der Bioinformatik bei der Genomsequenzierung.
Hierbei werden Emissionswahrscheinlichkeiten sowie Übergangswahrscheinlichkeiten zwischen den Zuständen berücksichtigt, um die wahrscheinlichste Sequenz zu bestimmen.

\medskip
\textbf{Notation:} 
Seien $i, j \in \{1, \ldots, N\}$ die Zustände und $o_1, \ldots, o_T$ die Beobachtungssequenz.
Die Übergangswahrscheinlichkeiten sind $a_{ij} = P(q_t = j \mid q_{t-1} = i)$, 
die Emissionswahrscheinlichkeiten $b_j(o_t) = P(o_t \mid q_t = j)$ und 
die Anfangsverteilung $\pi_i = P(q_1 = i)$.
Dabei bezeichnet $\delta_t(j)$ die maximale Pfadwahrscheinlichkeit bis zum Zeitpunkt $t$, die im Zustand $j$ endet, 
und $\psi_t(j)$ den optimalen Vorgängerzustand.

\paragraph{Initialisierung}
\begin{align}
  \delta_1(i) &= \pi_i \cdot b_i(o_1), \quad \text{für } i = 1, \ldots, N, \\
  \psi_1(i)   &= 0.
\end{align}

\paragraph{Rekursion}
Für $t = 2, \ldots, T$ und $j = 1, \ldots, N$:
\begin{align}
  \delta_t(j) &= \left[\max_{i \in \{1, \ldots, N\}} \delta_{t-1}(i) \cdot a_{ij} \right] \cdot b_j(o_t), \\
  \psi_t(j)   &= \arg\max_{i \in \{1, \ldots, N\}} \delta_{t-1}(i) \cdot a_{ij}.
\end{align}

\paragraph{Terminierung}
\begin{align}
  P^* &= \max_{i \in \{1, \ldots, N\}} \delta_T(i), \\
  q_T^* &= \arg\max_{i \in \{1, \ldots, N\}} \delta_T(i).
\end{align}

\paragraph{Rückverfolgung}
Für $t = T-1, T-2, \ldots, 1$:
\begin{equation}
  q_t^* = \psi_{t+1}(q_{t+1}^*).
\end{equation}

\paragraph{Logarithmiert (numerisch stabil)}
Um numerische Unterläufe zu vermeiden, kann der Algorithmus im Logarithmusbereich durchgeführt werden.
Definiere $\ell_t(j) = \log \delta_t(j)$. Dann gilt:

\textbf{Initialisierung:}
\begin{equation}
  \ell_1(i) = \log \pi_i + \log b_i(o_1), \quad \text{für } i = 1, \ldots, N.
\end{equation}

\textbf{Rekursion:}
Für $t = 2, \ldots, T$ und $j = 1, \ldots, N$:
\begin{align}
  \ell_t(j) &= \max_{i \in \{1, \ldots, N\}} [\ell_{t-1}(i) + \log a_{ij}] + \log b_j(o_t), \\
  \psi_t(j) &= \arg\max_{i \in \{1, \ldots, N\}} [\ell_{t-1}(i) + \log a_{ij}].
\end{align}

\textbf{Terminierung:}
\begin{align}
  P^* &= \max_{i \in \{1, \ldots, N\}} \ell_T(i), \\
  q_T^* &= \arg\max_{i \in \{1, \ldots, N\}} \ell_T(i).
\end{align}

\textbf{Rückverfolgung:}
\begin{equation}
  q_t^* = \psi_{t+1}(q_{t+1}^*), \quad \text{für } t = T-1, T-2, \ldots, 1.
\end{equation}

\begin{definition}[Beispieldefinition]
Dies ist eine Beispieldefinition.
\end{definition}
