%*****************************************
\chapter{Grundlagen}\label{ch:preliminaries}
%*****************************************

In diesem Kapitel werden die medizinischen und technischen Grundlagen erläutert, die für das Verständnis der Arbeit notwendig sind.
Dabei wird zuerst auf die medizinischen Hintergründe des behandelten Problems eingegangen.
Anschließend werden das technische Fundament der aktuellen Segmentierung sowie gängige Bildgebungsverfahren erläutert, die zur Lösung des Problems eingesetzt werden können.
Die verwendeten mathematischen Hintergründe und Theoreme werden ebenfalls in diesem Kapitel vorgestellt, um die theoretische Basis der Arbeit zu untermauern.

\section{Medizinischer Hintergrund}
Endoskopie ist eine der zentralen Behandlungs- und Diagnosemöglichkeiten in der Therapie von Darmkrebs, 
einer der häufigsten und tödlichsten Krebsarten.\citep{labianca2010-colon-cancer}\footnotemark{} 
Nicht von der Hand zu weisen ist hierbei die zeitaufwändige Durchführung und 
Dokumentation der Überwachung des flächigen Gewebes im Darm im Rahmen von Endoskopien. Aus diesem Grund ist es 
der Gastroenterologie konstant ein Anliegen, die Qualitätssicherung bei Darmspiegelungen zu verbessern. 
Wie in der Einleitung erwähnt, ist die Zökum-Rückzugszeit ein Beispiel für ein zuverlässiges Qualitätsmerkmal.  Hierbei ist es wichtig, dass die Darmspiegelung eine vorgeschriebene Zeit dauert, um die Chance auf eine vollständige Detektion aller möglichen Adenome zu erhöhen. 
Dadurch steigt die Wahrscheinlichkeit, dass die Darmspiegelung sorgfältig durchgeführt wurde, was nachweislich zu einer 
erhöhten Anzahl frührer Diagnosen führt und somit Todesfälle verhindern kann. Das liegt daran, dass die Durchführung von Darmspiegelungen sorgfältiger wird, wenn 
die Zeitvorgaben eingehalten werden.
Dieses Beispiel zeigt, dass wenn Qualitätskriterien eingehalten werden die Behandlungsqualität steigen kann. 
Die Europäische Gesellschaft für Gastroenterologie (ESGE) hat hierzu einige Forschungsfragen herausgegeben. Hierbei gibt es einige Punkte, speziell während der Endoskopie sowie in der Nachbereitung des Videomaterials, als auch weitergehend deren Umsetzung durch Nutzung eines KI-gestützten Systems zur Qualitätssicherung bei Darmspiegelungen profitieren könnten:

\begin{enumerate}
  \item \textbf{Vorbereitung der Prozedur}
    \begin{itemize}
      \item Welche Art von Intervention verbessert die Rate einer adäquaten Darmvorbereitung?
      \item Wie viel Zeit sollte für Screening- und diagnostische Koloskopien eingeplant werden?
    \end{itemize}

  \item \textbf{Vollständigkeit der Prozedur}
    \begin{itemize}
      \item Wie verhalten sich diagnostische Ausbeute (und Intervallkarzinomrate) in Abhängigkeit von einer steigenden Zökumintubationsrate?
      \item Welchen Nutzen hat die Dokumentation der Zökumintubation nur im schriftlichen Bericht im Vergleich zu einem schriftlichen \emph{und} fotografischen Bericht?
    \end{itemize}

  \item \textbf{Identifikation von Pathologien}
    \begin{itemize}
      \item Welcher Zielwert gilt für die Adenomdetektionsrate?
      \item Welches Leistungsmaß spiegelt die Identifikation von Pathologien außerhalb des CRC-Screening-/Überwachungssettings wider?
    \end{itemize}

  \item \textbf{Management von Pathologien}
    \begin{itemize}
      \item Was ist die verlässlichste und praktikabelste Methode, um die Vollständigkeit der Polypentfernung zu messen?
      \item Wie wirksam sind Zusatztechniken/-skalen (Chromendoskopie, Paris-Klassifikation, Tätowierung von Resektionsstellen) im Management von Pathologien?
    \end{itemize}

  \item \textbf{Komplikationen}
    \begin{itemize}
      \item Was ist die verlässlichste und praktikabelste Methode, um Komplikationsraten zu überwachen?
      \item Trägt die Überwachung dazu bei, Komplikationsraten zu senken?
    \end{itemize}
\end{enumerate}
\citep{kaminski-performance-2017}

Eine der Motivationen für ein zuverlässiges Segmentationsmodell für Endoskopievideos ist es, 
dass die Zökum-Rückzugszeit automatisch berechnet werden könnte. Wenn anhand der outside prediction der letzte Frame, 
der innerhalb des Körpers gefunden wird, festgestellt ist, ist die untere Schranke für den der Berechnung zugrundeliegenden Abschnitt des 
Videos bereits gegeben. Für die Berechnung der Zäkum-Rückzugszeit würde sich das so errechnete Upper Bound bei den Frames in dem Moment eignen, 
in dem auch das Zäkum vertrauenswürdig erkannt wird. Die zuverlässige Erkennung von Organteilen des Darms im Video ist 
Teil der endoskopischen Forschung mit künstlicher Intelligenz. Im speziellen die Erkennung von Polypen ist von besonderem Interesse. 
Diese Geschwulste wachsen als Vorstufe von potenziell bösartigen Tumoren an der Darminnenwand. Sie können aus verschiedenen Gründen und in verschiedenen Darmteilen auftreten, 
sind jedoch besonders als Frühmerkmal einer möglichen Diagnose von Darmkrebs interessant und deshalb wenn möglich vollständig zu erkennen. \citep{doi:10.7326/0003-4819-157-4-201208210-00002}
Weiter kompliziert wird die Erkennung und Einschätzung von Polypen dadurch, dass es verschiedene Stufen gibt.
Während bei einigen kolorektalen Polypen eine Darmblutung als Symptom auftritt, die zumeist eine schnelle Diagnose ermöglicht, sind andere Polypen asymptomatisch und werden nur zufällig bei einer routinemäßigen Darmspiegelung entdeckt.
Besonders bei diesen Fällen kann das Risiko bestehen, dass Polypen übersehen werden.
Unterschieden wird hierbei zwischen hochgradigen und niedergradigen Dysplasien. Diese Stufen bezeichnen den Grad der Zellveränderung in der Region des Polypen.
Besonders bei höhergradigen Dysplasien besteht das Risiko, dass ein maligner Polyp vorliegt.
Definitiv kann dies durch den Nachweis karzinogener Zellen innerhalb eines Polypen festgestellt werden. Hierbei handelt es sich um eine Aufgabe für die Pathologie,
die nach vollständiger Entfernung des betroffenen Gewebes erfolgen kann. \citep{Colucci261}
Auch bei der Zökum-Rückzugszeit ist das zentrale Kriterium, dass möglichst wenige Polypen übersehen werden sollen. 
Da durch den Einsatz von automatischer Erkennung dieser Vorkommnisse innerhalb des Darms eine erhebliche Beschleunigung dieses 
Prozesses möglich wäre, wird in diesem Bereich bereits seit Jahren geforscht. \citep{talukder-2022} 

Die Inferenz mit CNN basierten Modellen wie ResNet50 oder EfficientNetB0 hat sich in den letzten Jahren als sehr erfolgreich erwiesen.
Diese Modelle sind in der Lage, Bilddaten zu klassifizieren und können auch für die Segmentierung von Videos als Frames genutzt werden.
Die Ergebnisse dieser Klassifikation sind bei ausreichendem Training in einer kontinuierlichen Pipeline nutzbar.

\section{Technische und mathematische Grundlagen}

Dieses Kapitel wird die Herangehensweise an die mathematische Modellierung der Segmentierung von Endoskopievideos erläutern.
In diesem Kontext soll später im Kapitel Methodik herausgearbeitet werden, welche Modelle sich für eine statistisch haltbare Bewertung von Frameregionen eignen.

\subsubsection{Markov-Prozesse}

\enquote{Wir betrachten ein zufälliges dynamisches System. Sei $S : \mathbb{R} \to \mathbb{R}$ ein dynamisches System und definieren einen stochastischen Prozess $\{X_n\}_{n \ge 0}$ durch $X_{n+1} = S(X_n) + Y_n$, wobei $Y_0, Y_1, \dots$ unabhängige Zufallsvariablen mit Werten in $\mathbb{R}$ sind, die jeweils die gleiche Dichte $g$ haben, und $X_0$ und $\{Y_n\}_{n \ge 0}$ unabhängig sind. Dann ist der stochastische Prozess $\{X_n\}$ ein Markov-Prozess.} \citep[S.~13]{KhalilGhaffari2023}
Markov Prozesse sind laut dieser Definition Systeme aus Zuständen, die sich über die Zeit verändern.
Sie dürfen dabei nur von dem aktuellen Zustand abhängen und nicht von den vorherigen Zuständen.
Die Definition bezieht sich auf ein Stochastisches System und sieht deshalb eine Normierung der Werte im Bereich 0 bis 1 vor.
Die Zustände des Systems werden durch die Zufallsvariablen $X_n$ beschrieben.
\newline
Der Name der Markov-Prozesse stammt aus der Arbeit von A. A. Markov. Insbesondere interessant ist hier die Publikation \enquote{Beispiel von statistischer Forschung auf einem Text von \enquote{Eugene Onegin}, der interkonnektivität abhängiger Versuche in einer Kette klassifiziert.} \citep{markov-1913}.
Anhand eines Gedichts und der Verteilung der Konsonanten und Vokale untersuchte Markov hier, ob durch vielfache Wiederholung eines Zufallsexperiments, bei dem die Versuche voneinander abhängig sind, eine statistische Vorhersage getroffen werden kann. Dieser empirische Beweis greift eine frühere Publikation seinerseits auf, die theoretisch darlegt, dass das Gesetz der großen Zahlen auch auf abhängige
Zufallsvariablen anwendbar ist. Durch empirisches Messen der Häufigkeiten der Variablen erfasste Markov eine Übergangswahrscheinlichkeit. Diese konnte er im Nachgang einsetzen, um über diese Wahrscheinlichkeiten wiederum eine Buchstabenfolge zu generieren, bei der die Anzahl der Konsonanten und Vokale wieder auf einem Niveau einpendelten, das mit dem russischen Originaltext vergleichbar war.
Somit widerlegte er die These von Pawel Nekrassov, der die These aufgestellt hatte dass statistische Untersuchungen nur auf unabhängigen Variablen durchgeführt werden können, weil abhängige Größen durch den freien Willen beeinflusst sind. Diese These stützte er darauf, dass bei sozialen Statistiken wie der Rate der Hochzeiten in einer Gesellschaft in aufeinanderfolgenden Jahren oft ähnliche Hochzeitsraten auftreten. \citep{nekrasov-1912} Durch Markovs empiririschen Beweis seiner theoretischen Grundlage \citep{markov-1906} zeigte er, dass auch abhängige Variablen in oft wiederholten Zufallsexperimenten messbare Gesetzmäßigkeiten aufzeigen können.  Diese Idee wurde weiterentwickelt, um durch passende Modelle effiziente Vorhersagen über zukünftige Ereignisse treffen zu können.
Seine Arbeit hat bis heute großen Einfluss und findet sich auch in aktuellen Entwicklungen wie Recurrent Neural Networks wieder.

A. W. Drake beschreibt diskrete Markov-Prozesse als Kette von Zuständen, deren zukünftige Entwicklung nur vom aktuellen Zustand abhängt und deren Übergänge durch Übergangswahrscheinlichkeiten bestimmt werden \cite{drake88}.

\subsection{Sequenzielle Datenmodellierung mit Markov-Prozessen}

Die Modellierung sequenzieller Daten ist ein wichtiger Aspekt in vielen Bereichen der Informatik und Statistik, insbesondere in der Verarbeitung natürlicher Sprache, Zeitreihenanalyse und Bioinformatik. Sequenzielle Daten bestehen aus einer geordneten Folge von Elementen, bei denen die Reihenfolge der Elemente eine entscheidende Rolle spielt. Beispiele für sequenzielle Daten sind Textdokumente, DNA-Sequenzen und Zeitreihen von Messwerten.
Basierend auf der Entdeckung von Markov, wurden hierfür vielfältige Erweiterungen mit weitreichenden Anwendungen konzipiert.
Im Kontext von  und Hidden Markov Models (HMM) ist die Modellierung sequenzieller Daten besonders relevant, da diese Modelle darauf abzielen, die Abhängigkeiten zwischen aufeinanderfolgenden Zuständen in einer Sequenz zu erfassen.

Für die 1-Schritt-Übergangsmatrix $P$ gilt per Definition:
\begin{equation}
P_{ij} = P(X_{t+1} = j \mid X_t = i).
\end{equation}

Für eine 2-Schritt-Übergangswahrscheinlichkeit $P(X_{t+2} = j \mid X_t = i)$ müssen wir durch einen Zwischenzustand $k$ gehen:
\begin{equation}
P(X_{t+2} = j \mid X_t = i) = \sum_k P(X_{t+1} = k \mid X_t = i) \cdot P(X_{t+2} = j \mid X_{t+1} = k).
\end{equation}

Die Übergangswahrscheinlichkeiten können in einer Matrix $P$ zusammengefasst werden, wobei die Einträge $P_{ij}$ die Wahrscheinlichkeit angeben, vom Zustand $i$ in den Zustand $j$ überzugehen. Die Matrix $P$ wird als Übergangsmatrix bezeichnet und hat die Eigenschaft, dass die Summe der Einträge in jeder Zeile gleich 1 ist, da sie die gesamten Übergangswahrscheinlichkeiten von einem Zustand zu allen möglichen Zuständen repräsentiert.

In der Definition nimmt das Modell ein vollständig abgebildetes stochastisches Zufallsexperiment an. Es wird zudem davon ausgegangen, dass die Zustände des Systems vollständig beobachtbar sind. Einer einfachen Definition folgend, muss für jedes Label $y_i$ eines Frames $x_i$ die Wahrscheinlichkeit $P(y_i \mid x_i)$ modelliert werden.

\subsection{Markov Ketten}

Markov Ketten werden generell benutzt, um zeitlich aufeinanderfolgende Ereignisse zu modellieren. Hierfür werden Übergangswahrscheinlichkeiten definiert, die  Hierbei ist es in der einfachsten Version üblicherweise so, dass die anfänglichen Wahrscheinlichkeiten geschätzt oder gemessen werden.

\subsection{Markov Modelle}

Markov Modelle sind eine Klasse von statistischen Modellen, die verwendet werden, um Systeme zu modellieren, die sich über die Zeit verändern. Sie basieren auf der Annahme, dass der zukünftige Zustand eines Systems nur vom aktuellen Zustand abhängt und nicht von den vorherigen Zuständen. Dies wird als Markov-Eigenschaft bezeichnet.
Die Modelle werden als \enquote{Hidden} bezeichnet, da die zugrunde liegenden Zustände nicht direkt beobachtet werden können, sondern nur durch beobachtbare Ausgaben oder Emissionen inferiert werden.
\newline
HMM sind eine 
Generell handelt es sich bei HMM um ein generatives Modell, es wird also eine Wahrscheinlichkeit basierend auf dem zugrundeliegenden gelernten System abgebildet.
$P(X, Y)$


\subsection{Conditional Random Fields als generalisiertes Markov-Modell}

Conditional Random Fields (CRF) beschreiben eine Klasse von Modellen, mit denen sich Übergangswahrscheinlichkeiten darstellen lassen. Generell handelt es sich bei CRF um ein diskriminatives Modell, es wird also direkt die bedingte Wahrscheinlichkeit $P(Y|X)$ der Ausgabevariablen $Y$ gegeben die Eingabevariablen $X$ modelliert, anstatt der gemeinsamen Wahrscheinlichkeit $P(X, Y)$.
Diese Modellklasse ist die generalisierte Form von Markov Models. Hidden Markov Models beschreiben, wie im Kapitel erläutert, die Annahme, dass aufgrund von dem vorherigen versteckten Zustand das System vorhergesagt werden kann. Hierfür müsste jedoch das System von der Menge der versteckten Zustände vollständig beobachtbar sowie abbildbar sein.

\subsection{Non Markov Modelle}



\subsection{Chapman-Kolmogorov-Gleichung}

Die Chapman-Kolmogorov-Gleichung beschreibt, wie die Übergangswahrscheinlichkeit eines Markov-Prozesses über mehrere Zeitschritte hinweg berechnet werden kann. 
Dabei wird ein möglicher Zwischenzustand $k$ zu einem Zeitpunkt $m$ berücksichtigt, sodass die Wahrscheinlichkeit für einen Übergang von Zustand $i$ zu Zustand $j$ nach $n+m$ Schritten über die Gesamtheit aller Zwischenzustände dargestellt werden kann.

Für einen Markov-Prozess $\{X_t\}_{t \geq 0}$ mit Zustandsraum $S$ gilt für alle $i, j \in S$ und $n, m \geq 0$:
\begin{equation}
P(X_{n+m} = j \mid X_0 = i) = \sum_{k \in S} P(X_{n+m} = j \mid X_m = k, X_0 = i) \cdot P(X_m = k \mid X_0 = i).
\end{equation}

Mit Hilfe der Markov-Eigenschaft vereinfacht sich der erste Term, da der zukünftige Zustand $X_{n+m}$ nur vom aktuellen Zustand $X_m$ abhängt, nicht aber vom gesamten Verlauf bis $X_0 = i$:
\begin{equation}
P(X_{n+m} = j \mid X_m = k, X_0 = i) = P(X_{n+m} = j \mid X_m = k).
\end{equation}

Damit ergibt sich die Chapman-Kolmogorov-Gleichung in der üblichen Form:
\begin{equation}
P(X_{n+m} = j \mid X_0 = i) = \sum_{k \in S} P(X_{n+m} = j \mid X_m = k) \cdot P(X_m = k \mid X_0 = i).
\end{equation}

Schreibt man die Übergangswahrscheinlichkeiten in Matrixform, so entspricht dies der Aussage:
\begin{equation}
P^{(n+m)} = P^{(m)} \cdot P^{(n)},
\end{equation}
wobei $P^{(r)}$ die $r$-Schritt-Übergangsmatrix bezeichnet.

Über eine solche Übergangsmatrix können Vorhersagen über zukünftige Zustände eines Markov-Prozesses getroffen werden, indem die Matrix potenziert wird.
Das bedeutet, dass die $n$-Schritt-Übergangsmatrix $P^{(n)}$ durch die $n$-fache Multiplikation der 1-Schritt-Übergangsmatrix $P$ mit sich selbst berechnet werden kann:
\begin{equation}
P^{(n)} = \underbrace{P \cdot P \cdot \cdots \cdot P}_{n \text{ Mal}} = P^n.
\end{equation} 


\subsection{Viterbi-Dekodierung}

Der Viterbi-Algorithmus ist ein dynamischer Programmieralgorithmus, der verwendet wird, um die wahrscheinlichste Sequenz von versteckten Zuständen in einem Hidden Markov Model (HMM) zu finden, basierend auf einer gegebenen Sequenz von beobachteten Ereignissen. Der Algorithmus wurde von Andrew Viterbi 1967 erstmals vorgeschlagen und ist besonders nützlich in Anwendungen, bei denen sequenzielle Daten auftreten, deren Zusammensetzung Schlüsse auf die zugrundeliegenden wahren Zustände zulassen. Die Fähigkeit, aus den beobachtbaren Zuständen auf versteckte Wahrheiten schließen zu können, macht den Viterbi-Algorithmus praxisrelevant in vielen Bereichen, wie in der Elektrotechnik bei der Analyse von Kommunikationssystemen oder in der Bioinformatik bei der Genomsequenzierung.
Hierbei werden Emissionswahrscheinlichkeiten sowie Übergangswahrscheinlichkeiten zwischen den Zuständen berücksichtigt, um die wahrscheinlichste Sequenz zu bestimmen.

\medskip
\textbf{Notation:} 
Seien $i, j \in \{1, \ldots, N\}$ die Zustände und $o_1, \ldots, o_T$ die Beobachtungssequenz.
Die Übergangswahrscheinlichkeiten sind $a_{ij} = P(q_t = j \mid q_{t-1} = i)$, 
die Emissionswahrscheinlichkeiten $b_j(o_t) = P(o_t \mid q_t = j)$ und 
die Anfangsverteilung $\pi_i = P(q_1 = i)$.
Dabei bezeichnet $\delta_t(j)$ die maximale Pfadwahrscheinlichkeit bis zum Zeitpunkt $t$, die im Zustand $j$ endet, 
und $\psi_t(j)$ den optimalen Vorgängerzustand.

\paragraph{Initialisierung}
\begin{align}
  \delta_1(i) &= \pi_i \cdot b_i(o_1), \quad \text{für } i = 1, \ldots, N, \\
  \psi_1(i)   &= 0.
\end{align}

\paragraph{Rekursion}
Für $t = 2, \ldots, T$ und $j = 1, \ldots, N$:
\begin{align}
  \delta_t(j) &= \left[\max_{i \in \{1, \ldots, N\}} \delta_{t-1}(i) \cdot a_{ij} \right] \cdot b_j(o_t), \\
  \psi_t(j)   &= \arg\max_{i \in \{1, \ldots, N\}} \delta_{t-1}(i) \cdot a_{ij}.
\end{align}

\paragraph{Terminierung}
\begin{align}
  P^* &= \max_{i \in \{1, \ldots, N\}} \delta_T(i), \\
  q_T^* &= \arg\max_{i \in \{1, \ldots, N\}} \delta_T(i).
\end{align}

\paragraph{Rückverfolgung}
Für $t = T-1, T-2, \ldots, 1$:
\begin{equation}
  q_t^* = \psi_{t+1}(q_{t+1}^*).
\end{equation}

\paragraph{Logarithmiert (numerisch stabil)}
Um numerische Unterläufe zu vermeiden, kann der Algorithmus im Logarithmusbereich durchgeführt werden.
Definiere $\ell_t(j) = \log \delta_t(j)$. Dann gilt:

\textbf{Initialisierung:}
\begin{equation}
  \ell_1(i) = \log \pi_i + \log b_i(o_1), \quad \text{für } i = 1, \ldots, N.
\end{equation}

\textbf{Rekursion:}
Für $t = 2, \ldots, T$ und $j = 1, \ldots, N$:
\begin{align}
  \ell_t(j) &= \max_{i \in \{1, \ldots, N\}} [\ell_{t-1}(i) + \log a_{ij}] + \log b_j(o_t), \\
  \psi_t(j) &= \arg\max_{i \in \{1, \ldots, N\}} [\ell_{t-1}(i) + \log a_{ij}].
\end{align}

\textbf{Terminierung:}
\begin{align}
  P^* &= \max_{i \in \{1, \ldots, N\}} \ell_T(i), \\
  q_T^* &= \arg\max_{i \in \{1, \ldots, N\}} \ell_T(i).
\end{align}

\textbf{Rückverfolgung:}
\begin{equation}
  q_t^* = \psi_{t+1}(q_{t+1}^*), \quad \text{für } t = T-1, T-2, \ldots, 1.
\end{equation}

\begin{definition}[Beispieldefinition]
Dies ist eine Beispieldefinition.
\end{definition}
